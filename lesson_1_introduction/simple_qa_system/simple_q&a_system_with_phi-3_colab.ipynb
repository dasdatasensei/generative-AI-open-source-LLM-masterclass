{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Complete GenAI & RAG Masterclass\n",
    "## Introduction to GenAI with Open-Source LLMs\n",
    "### Project: Simple Q&A System with Phi-3\n",
    "\n",
    "**Author:** Dr. Jody-Ann S. Jones\n",
    "**GitHub:** [github.com/dasdatasensei](https://github.com/dasdatasensei)\n",
    "\n",
    "This notebook is designed for Google Colab with GPU acceleration.\n",
    "For local development in VSCode, see the companion `simple_q&a_system_with_phi-3.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment\n",
    "\n",
    "First, let's ensure we have all the necessary libraries installed and configure GPU access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'GPU available: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'CUDA Version: {torch.version.cuda}')\n",
    "    print(f'Memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB')\n",
    "    print(f'Memory reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU available, using CPU. Performance will be limited.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers accelerate bitsandbytes sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Now let's import the libraries we'll need for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mount Google Drive (Optional)\n",
    "\n",
    "If you want to save your work or use data from your Google Drive, uncomment and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Implementation\n",
    "\n",
    "Your implementation will go here..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}